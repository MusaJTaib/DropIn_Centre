{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "start_time = time.time()\n",
    "import random\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from functools import reduce\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Windows: 1,2,3,6,12,22,45,90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfWindows = 1\n",
    "Restriction = '90'\n",
    "ep = 125\n",
    "numberOfFeatures = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "los_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSetB2 = pd.DataFrame()\n",
    "FeatureSetB3 = pd.DataFrame()\n",
    "FeatureSetB4 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSet1 = pd.read_csv('DI/DATA_Base.csv') #Split\n",
    "FeatureSet2 = pd.read_csv(f'DI/DATA_{numberOfWindows}.csv')#Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSetB2 = pd.DataFrame()\n",
    "FeatureSetB1 = pd.DataFrame()\n",
    "FeatureSetB4 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSetB2['SubjectId'] = FeatureSet2['subject_id']\n",
    "FeatureSetB2['BT'] = FeatureSet2['sleep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSet1['SubjectId'] = FeatureSet1['subject_id']\n",
    "FeatureSetB1 = FeatureSet1.drop(['sleep','subject_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FeatureSetB1.drop(\"ssAgg\",axis=1,inplace = True)\n",
    "FeatureSetB1.drop(\"usAgg\",axis=1,inplace = True)\n",
    "FeatureSetB1.drop(\"isAgg\",axis=1,inplace = True)\n",
    "FeatureSetB1.drop(\"dsAgg\",axis=1,inplace = True)\n",
    "FeatureSetB1.drop(\"disAgg\",axis=1,inplace = True)\n",
    "\n",
    "\n",
    "FeatureSetB1 = FeatureSetB1.fillna(0)\n",
    "FeatureSetB2 = FeatureSetB2.fillna(0)\n",
    "\n",
    "FeatureMortality2 = pd.read_csv('DI/Sleep_Tbl.csv') #Labels\n",
    "FeatureMortality = pd.DataFrame()\n",
    "FeatureMortality['SubjectId'] = FeatureMortality2['ClientId']\n",
    "FeatureMortality['Death'] = FeatureMortality2['Flags']\n",
    "\n",
    "FeatureSetB1.sort_values(by=['SubjectId'], ascending=True,inplace=True)\n",
    "FeatureSetB2.sort_values(by=['SubjectId'], ascending=True,inplace=True)\n",
    "\n",
    "FeatureMortality.sort_values(by=['SubjectId'], ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Chronic is 1        #Episodic is 2       #Transitional is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureMortality.Death[FeatureMortality.Death == 2] = 0      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SubjectId = pd.DataFrame()\n",
    "SubjectId = FeatureSetB1.SubjectId\n",
    "SubjectId.drop_duplicates(keep = 'first', inplace = True)\n",
    "SubjectId.reset_index(drop=True,inplace=True)\n",
    "NumSubjects = len(SubjectId)\n",
    "X = FeatureMortality['SubjectId'].equals(SubjectId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = FeatureMortality['SubjectId'].isin(SubjectId)\n",
    "FeatureMortality = FeatureMortality[X]\n",
    "FeatureMortality.sort_values(by=['SubjectId'], ascending=True,inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = pd.DataFrame()\n",
    "Labels['SubjectId'] = FeatureMortality['SubjectId']\n",
    "Labels['Expired'] = FeatureMortality['Death']\n",
    "y = Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['Expired'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SubjectId = pd.DataFrame()\n",
    "SubjectId = y.SubjectId\n",
    "SubjectId.drop_duplicates(keep = 'first', inplace = True)\n",
    "SubjectId.reset_index(drop=True,inplace=True)\n",
    "X = FeatureSetB1['SubjectId'].isin(SubjectId)\n",
    "FeatureSetB1 = FeatureSetB1[X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = FeatureSetB1\n",
    "X_1 = [X,y]\n",
    "\n",
    "X_2 = reduce(lambda  left,right: pd.merge(left,right,on=['SubjectId'],how='outer'), X_1)\n",
    "X_2.sort_values(by=['SubjectId'], ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = FeatureSetB1\n",
    "\n",
    "X_train1, X_test = train_test_split(X_2, test_size=0.2, random_state=42, stratify=X_2[['Expired']], shuffle=True)#,'AIDS','MetaStatic','Hematologic'#,'GCSEyes']]\n",
    "\n",
    "X_train, X_val = train_test_split(X_train1, test_size=0.2, random_state=42, stratify=X_train1[['Expired']], shuffle=True)#, shuffle=True)#,'GCSEyes']],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['Expired'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val['Expired'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Expired'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subject_Test = pd.DataFrame()\n",
    "Subject_Test = X_test.SubjectId\n",
    "Subject_Test.drop_duplicates(keep = 'first', inplace = True)\n",
    "\n",
    "Subject_Train = pd.DataFrame()\n",
    "Subject_Train = X_train.SubjectId\n",
    "Subject_Train.drop_duplicates(keep = 'first', inplace = True)\n",
    "\n",
    "Subject_Val = pd.DataFrame()\n",
    "Subject_Val = X_val.SubjectId\n",
    "Subject_Val.drop_duplicates(keep = 'first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = FeatureMortality['SubjectId'].isin(Subject_Train)\n",
    "y_train = FeatureMortality[X]\n",
    "\n",
    "X = FeatureMortality['SubjectId'].isin(Subject_Test)\n",
    "y_test = FeatureMortality[X]\n",
    "\n",
    "X = FeatureMortality['SubjectId'].isin(Subject_Val)\n",
    "y_val = FeatureMortality[X]\n",
    "\n",
    "y_train = y_train.drop(['SubjectId'], axis=1)\n",
    "y_test = y_test.drop(['SubjectId'], axis=1)\n",
    "y_val = y_val.drop(['SubjectId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = FeatureSetB1['SubjectId'].isin(Subject_Train)\n",
    "X_train = FeatureSetB1[X]\n",
    "X2 = FeatureSetB2['SubjectId'].isin(Subject_Train)\n",
    "X_train2 = FeatureSetB2[X2]\n",
    "\n",
    "X = FeatureSetB1['SubjectId'].isin(Subject_Test)\n",
    "X_test = FeatureSetB1[X]\n",
    "X2 = FeatureSetB2['SubjectId'].isin(Subject_Test)\n",
    "X_test2 = FeatureSetB2[X2]\n",
    "\n",
    "X = FeatureSetB1['SubjectId'].isin(Subject_Val)\n",
    "X_val = FeatureSetB1[X]\n",
    "X2 = FeatureSetB2['SubjectId'].isin(Subject_Val)\n",
    "X_val2 = FeatureSetB2[X2]\n",
    "\n",
    "X_train.sort_values(by=['SubjectId'], ascending=True,inplace=True)\n",
    "X_train2.sort_values(by=['SubjectId'], ascending=True,inplace=True)\n",
    "\n",
    "X_test.sort_values(by=['SubjectId'], ascending=True,inplace=True)\n",
    "X_test2.sort_values(by=['SubjectId'], ascending=True,inplace=True)\n",
    "\n",
    "X_val.sort_values(by=['SubjectId'], ascending=True,inplace=True)\n",
    "X_val2.sort_values(by=['SubjectId'], ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['SubjectId','index_id','Unnamed: 0'], axis=1)\n",
    "X_test = X_test.drop(['SubjectId','index_id','Unnamed: 0'], axis=1)\n",
    "X_val = X_val.drop(['SubjectId','index_id','Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train2.drop(['SubjectId'], axis=1)\n",
    "X_test2 = X_test2.drop(['SubjectId'], axis=1)\n",
    "X_val2 = X_val2.drop(['SubjectId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_shape = X_train.shape\n",
    "Test_shape = X_test.shape\n",
    "Val_shape = X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "X_train2 = X_train2.to_numpy()\n",
    "\n",
    "X_test = X_test.to_numpy()\n",
    "X_test2 = X_test2.to_numpy()\n",
    "\n",
    "X_val = X_val.to_numpy()\n",
    "X_val2 = X_val2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train2.reshape(int(Train_shape[0]),numberOfWindows*numberOfFeatures)\n",
    "X_test2 = X_test2.reshape(int(Test_shape[0]),numberOfWindows*numberOfFeatures)\n",
    "X_val2 = X_val2.reshape(int(Val_shape[0]),numberOfWindows*numberOfFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train4 = np.concatenate((X_train2, X_train), axis=1)\n",
    "\n",
    "X_test4 = np.concatenate((X_test2, X_test), axis=1)\n",
    "\n",
    "X_val4 = np.concatenate((X_val2, X_val), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train['Death']\n",
    "y_train = y_train.to_numpy()\n",
    "y_train = y_train.flatten()\n",
    "\n",
    "y_test = y_test['Death']\n",
    "y_test = y_test.to_numpy()\n",
    "y_test = y_test.flatten()\n",
    "\n",
    "y_val = y_val['Death']\n",
    "y_val = y_val.to_numpy()\n",
    "y_val = y_val.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import sys\n",
    "mod=sys.modules[__name__]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 45, mode='min',restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "acc_score = []\n",
    "re_score = []\n",
    "pre_score = []\n",
    "history_1 = []\n",
    "f_score = []\n",
    "acc_macro_score = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfFeatures2 = X_test4.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler1 = StandardScaler().fit(X_train4)\n",
    "scaler2 = StandardScaler().fit(X_test4)\n",
    "scaler3 = StandardScaler().fit(X_val4)\n",
    "\n",
    "X_train4 = scaler1.transform(X_train4)\n",
    "X_test4 = scaler2.transform(X_test4)\n",
    "X_val4 = scaler3.transform(X_val4)\n",
    "\n",
    "\n",
    "\n",
    "for x in range(40):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.Input(shape=(numberOfFeatures2,))) #(numberOfFeatures,)\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    opt = tf.keras.optimizers.legacy.Adam()#, decay=1e-3) #If validation is not following training in trend then the learning rate might be too high\n",
    "    model.compile(loss='binary_crossentropy',optimizer=opt, metrics=['accuracy'])#focal_loss_custom(alpha=0.2, gamma=2) #'binary_crossentropy'#focal_loss_custom(alpha=0.25, gamma=2)\n",
    "\n",
    "\n",
    "    class_weights = class_weight.compute_class_weight(class_weight ='balanced',classes = np.unique(y_train),y = y_train)\n",
    "    class_weights = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "    history = model.fit(X_train4,y_train, epochs = ep,batch_size=256,validation_data=(X_val4, y_val), callbacks=[stop_early],shuffle=True,class_weight=class_weights)#,use_multiprocessing=True\n",
    "    history_1.append(history)\n",
    "\n",
    "    y_preds = model.predict(X_test4)\n",
    "    y_preds = y_preds.flatten()\n",
    "    y_pred = list(map(lambda x: 0 if x<0.5 else 1, y_preds))\n",
    "\n",
    "    y_actu = pd.Series(y_test)\n",
    "    y_pred = pd.Series(y_pred)\n",
    "        \n",
    "    sensitivity = recall_score(y_actu, y_pred,average='macro')#,pos_label = 1, average='binary')\n",
    "    precision = precision_score(y_actu, y_pred,average='macro')#,pos_label = 1, average='binary')\n",
    "    f1_value = f1_score(y_actu, y_pred,average='macro')#,pos_label = 1, average='binary')\n",
    "    accuracy = accuracy_score(y_actu, y_pred)\n",
    "\n",
    "    acc_score.append(accuracy)\n",
    "    re_score.append(sensitivity)\n",
    "    pre_score.append(precision)\n",
    "    f_score.append(f1_value)\n",
    "    \n",
    "    matrix = matrix2 = confusion_matrix(y_actu, y_pred)\n",
    "    cm_display = ConfusionMatrixDisplay(confusion_matrix = matrix2)\n",
    "    matrix.diagonal()/matrix.sum(axis=1)\n",
    "    Accuracies = matrix.diagonal()/matrix.sum(axis=1)\n",
    "    Less10D = Accuracies[0]\n",
    "    Greater10D = Accuracies[1]\n",
    "    Accuracies = matrix.diagonal()/matrix.sum(axis=1)\n",
    "    accuracy_macro = (Greater10D+Less10D)/2\n",
    "    acc_macro_score.append(accuracy_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 40\n",
    "avg_acc_score = sum(acc_score)/k\n",
    "avg_recall_score = sum(re_score)/k\n",
    "avg_precision_score = sum(pre_score)/k\n",
    "avg_f1_score = sum(f_score)/k\n",
    "avg_acc_macro_score = sum(acc_macro_score)/k\n",
    "\n",
    "accuracy_macro = avg_acc_macro_score\n",
    "sensitivity = avg_recall_score\n",
    "precision = avg_precision_score\n",
    "accuracy = avg_acc_score\n",
    "f1_score = avg_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def calculate_standard_deviation(numbers):\n",
    "    n = len(numbers)\n",
    "    mean = sum(numbers) / n\n",
    "    variance = sum((x - mean) ** 2 for x in numbers) / n\n",
    "    std_dev = math.sqrt(variance)\n",
    "    return std_dev\n",
    "\n",
    "std_acc = calculate_standard_deviation(acc_score)\n",
    "std_acc_macro = calculate_standard_deviation(acc_macro_score)\n",
    "std_recall = calculate_standard_deviation(re_score)\n",
    "std_precision = calculate_standard_deviation(pre_score)\n",
    "std_f1_score = calculate_standard_deviation(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_min = min(re_score)\n",
    "sensitivity_max = max(re_score)\n",
    "\n",
    "precision_min = min(pre_score)\n",
    "precision_max = max(pre_score)\n",
    "\n",
    "accuracy_min = min(acc_score)\n",
    "accuracy_max = max(acc_score)\n",
    "\n",
    "accuracy_macro_min = min(acc_macro_score)\n",
    "accuracy_macro_max = max(acc_macro_score)\n",
    "\n",
    "f1_score_min = min(f_score)\n",
    "f1_score_max = max(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Avg accuracy : {}'.format(avg_acc_score))\n",
    "print('Avg Reccall : {}'.format(avg_recall_score))\n",
    "print('Avg Precision : {}'.format(avg_precision_score))\n",
    "print('Avg F1_score : {}'.format(avg_f1_score))\n",
    "print('Avg accuracy_macro : {}'.format(avg_acc_macro_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for history in history_1:\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for history in history_1:\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "\n",
    "csv_columns = ['model-type','precision','sensitivity','f1-score','accuracy','accuracy_macro','NumberOfWindows','Epochs','Run_Time','Restriction','Acc_Lesser','Acc_Greater']\n",
    "dict_data = [{'model-type':'ANN', 'precision': precision,'sensitivity': sensitivity,'f1-score': f1_score,'accuracy': accuracy,'accuracy_macro': accuracy_macro,'NumberOfWindows':numberOfWindows,\"Epochs\":ep,'Run_Time':runtime,'Restriction' : Restriction,'Acc_Lesser':Less10D,'Acc_Greater':Greater10D}]\n",
    "metric_file = \"Results/Chronic_ANN_Mid_Multi_1_Norm.csv\"\n",
    "\n",
    "file_exists = os.path.isfile(metric_file)\n",
    "try:\n",
    "    with open(metric_file, 'a') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        for data in dict_data:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
