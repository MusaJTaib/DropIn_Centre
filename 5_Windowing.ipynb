{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71a4b023",
   "metadata": {},
   "source": [
    "\n",
    "# Data Analysis and Windowing Techniques\n",
    "\n",
    "This notebook demonstrates the application of windowing techniques in data analysis, focusing on preprocessing and target variable generation. The process includes setting up the environment, loading libraries, and initial data pre-processing steps. The aim is to prepare the data for further analysis, applying windowing techniques to segment data over specified intervals for detailed examination.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the number of days for the shelter interaction timeline (range: 1-90 days)\n",
    "numberOfDays = 90\n",
    "\n",
    "# Set the number of windows for analysis (can be modified to change analysis granularity)\n",
    "numberOfWindows = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loading necessary Python libraries and setting up environment for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "# Importing standard data analysis and visualization libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime, copy, imp\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from tqdm.auto import tqdm, trange\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Adding project-specific utility functions to the Python path\n",
    "import sys\n",
    "sys.path.insert(0, '../util/')\n",
    "\n",
    "# Auto-import for specific modules to ensure they are reloaded before execution\n",
    "%aimport di_data\n",
    "%aimport data_cache\n",
    "\n",
    "from di_data import *\n",
    "from data_cache import CacheResult\n",
    "\n",
    "# Recording the start time of preprocessing\n",
    "pre_start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Pre-Processing for Target Variable\n",
    "\n",
    "In this section, we generate the target variable based on methodologies outlined in referenced notebooks by Dr. Messier and Caleb. This includes the pre-processing of attributes to suit the analysis needs, ensuring data is correctly formatted and ready for further processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Directory paths configuration for data and cache folders\n",
    "dirStr = ''   # Path to the data folder\n",
    "cacheStr = '../cache/'   # Path to the cache folder for storing intermediate results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@CacheResult\n",
    "def PreProcess():\n",
    "    \n",
    "    tblAll = pd.read_hdf(dirStr + 'UniversityExportAnonymized.hd5')\n",
    "\n",
    "    tbl = copy.deepcopy(tblAll[ [ 'ClientId', 'Date', 'EntryType', 'Age' ] ])\n",
    "    tbl['Police'] = (tblAll.PoliceLogFlag == 1) | (tblAll.CPS > 0)\n",
    "    tbl['Ems'] = (tblAll.EmsLogFlag == 1) | (tblAll.EMS > 0)\n",
    "    tbl['Health'] = (tblAll.Health > 0) | (tblAll.PhysicalHealth > 0) | (tblAll.MentalHealth > 0) | (tblAll.Medication > 0)\n",
    "    tbl['Violence'] = (tblAll.PhysicalViolence > 0) | (tblAll.Weapon > 0) | (tblAll.Spray > 0) | (tblAll.Brawl > 0) | (tblAll.Gun > 0) | (tblAll.Knife > 0)\n",
    "    tbl['Addiction'] = (tblAll.Addiction > 0) | (tblAll.Overdose > 0)    \n",
    "    \n",
    "    \n",
    "    leftStart = tbl.Date.min()\n",
    "    leftEnd = pd.to_datetime('2009-07-01')\n",
    "    \n",
    "    rightStart = pd.to_datetime('2018-01-06')  \n",
    "    rightEnd = tbl.Date.max()\n",
    "    \n",
    "    nClientsAll = len(tbl.ClientId.unique())\n",
    "    \n",
    "    tbl = RemoveByStartDate(tbl,leftStart,leftEnd,tbl.EntryType == 'Sleep')\n",
    "    nLeftRemoved = nClientsAll - len(tbl.ClientId.unique())\n",
    "\n",
    "    tbl = RemoveByStartDate(tbl,rightStart,rightEnd,tbl.EntryType == 'Sleep')\n",
    "    nRightRemoved = nClientsAll - nLeftRemoved - len(tbl.ClientId.unique())\n",
    "\n",
    "    \n",
    "    tbl = tbl.loc[tbl.Date >= pd.to_datetime('2008-09-01')]\n",
    "\n",
    "    nClients = len(tbl.ClientId.unique())\n",
    " \n",
    "    print('Total Clients: {:d}/{:d} ({:d} removed left, {:d} removed right)'\n",
    "          .format(nClients,nClientsAll,nLeftRemoved,nRightRemoved))\n",
    "\n",
    "    return tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = PreProcess(path=cacheStr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Chronic Shelter Users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a timeline of stays for each client in order to determine who satisfies the DI chronic shelter use definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@CacheResult\n",
    "def GenerateStayTimelines():\n",
    "    return tbl.loc[tbl.EntryType=='Sleep'].groupby('ClientId').progress_apply(CalculateStaySequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlSty = GenerateStayTimelines(path=cacheStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TimeToChronic(tbl,thresh,winSzDays):\n",
    "    \n",
    "    win = tbl.rolling('%dd' % winSzDays,on='Date').count().Ind\n",
    "    \n",
    "    registrationDate = tbl.Date.min()\n",
    "    idDate = tbl[win >= thresh].Date.min()  # Will be equal to NaN if the threshold isn't met.\n",
    "    \n",
    "    if idDate == idDate:   # Satisfied if idDate is not NaN.\n",
    "        return pd.Series({\n",
    "            'Flag': 'chr',  # Flag indicating test was satisfied.\n",
    "            'Date': idDate,   # Date client was identified.\n",
    "            'Time': (idDate - registrationDate).days + 1 # Number of days it took to identify client.\n",
    "        })\n",
    "    else:\n",
    "        return pd.Series({   # Returned if the test is not satisfied.\n",
    "            'Flag': 'tmp',\n",
    "            'Date': tbl.Date.max(),\n",
    "            'Time': (tbl.Date.max()-tbl.Date.min()).days + 1\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@CacheResult\n",
    "def DiChronicTte():\n",
    "    return tlSty.groupby('ClientId').progress_apply(TimeToChronic,thresh=276,winSzDays=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tteDi = DiChronicTte(path=cacheStr)  # To Generate Labels for each Client ID {'chr' or 'tmp'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@CacheResult\n",
    "def CalculateClientDemographics():\n",
    "    return tbl.groupby('ClientId').progress_apply(ShelterGroupDemographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demog = CalculateClientDemographics(path=cacheStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrintStats(demog,cohortInd): \n",
    "    cohort = demog.loc[cohortInd]\n",
    "    \n",
    "    nPop = len(demog.index)\n",
    "    nCohort = len(cohort.index)\n",
    "    print( 'Clients in cohort: %d/%d (%.1f%%)' % (nCohort,nPop,100*nCohort/nPop))\n",
    "\n",
    "    fields = [ 'Tenure', 'UsagePct', 'AvgGapLen', 'TotalStays', 'TotalEpisodes' ]\n",
    "    for field in fields:\n",
    "        print('%s:' % (field))\n",
    "        nEntry = sum(~np.isnan(cohort[field]))                \n",
    "        print(' Avg: {:.1f}, Med: {:.1f}, 10thPct: {:.1f}, 90thPct: {:.1f}' \n",
    "              .format(cohort[field].mean(),cohort[field].median(),\n",
    "                    cohort[field].sort_values().iloc[int(nEntry*0.1)],\n",
    "                    cohort[field].sort_values().iloc[int(nEntry*0.9)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrintStats(demog,tteDi.loc[tteDi.Flag=='chr'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrintStats(demog,tteDi.loc[tteDi.Flag=='tmp'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tteDi[tteDi.Flag=='chr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('clientTsTables90DaysPaddedDF.h5')\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Day < numberOfDays+1]\n",
    "df = df.set_index(['ClientId','Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(level=[0,1])\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AgeFix(tbl):\n",
    "    fix =    tbl.Age + tbl.Date.dt.year - 2020.0\n",
    "    return fix\n",
    "newAge = df.groupby(\"ClientId\").progress_apply(AgeFix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newAge = pd.DataFrame(newAge)\n",
    "newAge = newAge.reset_index(level=[0,1])\n",
    "newAge= newAge.rename(columns={0:'Age_fix'})\n",
    "newAge = newAge.drop(columns=['level_1'])\n",
    "df['AgeFix']=newAge.Age_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)  # Zero-Imputing the NaN values\n",
    "nClients = len(df.ClientId.unique())\n",
    "df = df.drop(columns=['Date','Day','Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['ClientId','EncodedVector','AgeFix','EmployeeId','EmployeeIsCounsellor','BarDuration','SleepEntry','LogEntry','CounsellorNotes','ProgressDetails','SoberState','UnderState','IntoxicatedState','DruggedState','DruggedIntoxicatedState','PoliceLogFlag','EmsLogFlag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,pd.get_dummies(df['BarDuration'], prefix='Bar')],axis=1) #dummy_na=True currently false\n",
    "df.drop(['BarDuration'],axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.rename(columns = {'Bar_1.0': 'Bar_1', 'Bar_2.0': 'Bar_2','Bar_3.0':'Bar_3','Bar_5.0':'Bar_5','Bar_7.0':'Bar_7','Bar_14.0':'Bar_14','Bar_21.0':'Bar_21','Bar_30.0':'Bar_30','Bar_60.0':'Bar_60','Bar_90.0':'Bar_90','Bar_120.0':'Bar_120','Bar_180.0':'Bar_180','Bar_-24 Hours':'Bar_24Hours'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregationFunc(tbl):\n",
    "    empAgg = tbl.EmployeeId.sum()\n",
    "    emcAgg = tbl.EmployeeIsCounsellor.sum()\n",
    "    sleepAgg = tbl.SleepEntry.sum()\n",
    "    logAgg = tbl.LogEntry.sum()\n",
    "    notesAgg = tbl.CounsellorNotes.sum()\n",
    "    detailsAgg = tbl.ProgressDetails.sum()\n",
    "    ssAgg = tbl.SoberState.sum()                 \n",
    "    usAgg = tbl.UnderState.sum()                 \n",
    "    isAgg = tbl.IntoxicatedState.sum()           \n",
    "    dsAgg = tbl.DruggedState.sum()               \n",
    "    disAgg = tbl.DruggedIntoxicatedState.sum()   \n",
    "    policeAgg = tbl.PoliceLogFlag.sum()         \n",
    "    emsAgg = tbl.EmsLogFlag.sum()               \n",
    "    bar0Agg = tbl.Bar_0.sum()                       \n",
    "    bar1Agg = tbl.Bar_1.sum()                  \n",
    "    bar2Agg = tbl.Bar_2.sum()                   \n",
    "    bar3Agg = tbl.Bar_3.sum()                   \n",
    "    bar5Agg = tbl.Bar_5.sum()                   \n",
    "    bar7Agg = tbl.Bar_7.sum()               \n",
    "    bar14Agg = tbl.Bar_14.sum()\n",
    "    bar21Agg = tbl.Bar_21.sum()   \n",
    "    bar30Agg = tbl.Bar_30.sum()   \n",
    "    bar60Agg = tbl.Bar_60.sum()   \n",
    "    bar90Agg = tbl.Bar_90.sum()       \n",
    "    bar120Agg = tbl.Bar_120.sum()         \n",
    "    bar180Agg = tbl.Bar_180.sum()\n",
    "    bar24HAgg = tbl.Bar_24Hours.sum()          \n",
    "    barCondAgg = tbl.Bar_Conditional.sum()          \n",
    "    barLifeAgg = tbl.Bar_Life.sum()                 \n",
    "    barWarningAgg = tbl.Bar_Warning.sum()\n",
    "    ageAgg = tbl.AgeFix.max()\n",
    "    return pd.Series({\n",
    "    'age': ageAgg,\n",
    "    'emp': empAgg,\n",
    "    'emc' : emcAgg,\n",
    "    'sleep' : sleepAgg,\n",
    "    'logAgg' : logAgg,\n",
    "    'notesAgg' :  notesAgg,\n",
    "    'detailsAgg' : detailsAgg,\n",
    "    'ssAgg' : ssAgg,              \n",
    "    'usAgg': usAgg,                  \n",
    "    'isAgg': isAgg,            \n",
    "    'dsAgg': dsAgg,                \n",
    "    'disAgg': disAgg,\n",
    "    'policeAgg': policeAgg,         \n",
    "    'emsAgg': emsAgg,              \n",
    "    'bar0Agg': bar0Agg,                      \n",
    "    'bar0Agg': bar1Agg,                  \n",
    "    'bar2Agg' : bar2Agg,                   \n",
    "    'bar3Agg': bar3Agg,                  \n",
    "    'bar5Agg': bar5Agg,                   \n",
    "    'bar7Agg': bar7Agg,              \n",
    "    'bar14Agg': bar14Agg, \n",
    "    'bar21Agg': bar21Agg,   \n",
    "    'bar30Agg': bar30Agg,   \n",
    "    'bar60Agg': bar60Agg,   \n",
    "    'bar90Agg': bar90Agg,        \n",
    "    'bar120Agg': bar120Agg,         \n",
    "    'bar90Agg': bar90Agg, \n",
    "    'bar24HAgg': bar24HAgg,          \n",
    "    'barCondAgg': barCondAgg,           \n",
    "    'barLifeAgg': barLifeAgg,                 \n",
    "    'barWarningAgg': barWarningAgg \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy(deep=True)\n",
    "df2 = df2.groupby(\"ClientId\").progress_apply(aggregationFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subject_id = pd.DataFrame()\n",
    "Subject_id = df.ClientId\n",
    "Subject_id.drop_duplicates(keep = 'first', inplace = True)\n",
    "Subject_id.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar \n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "WSUsed = []\n",
    "for rows in range(numberOfWindows):\n",
    "        IndexPerWindowLower = np.floor(numberOfDays/numberOfWindows)\n",
    "        IndexPerWindowUpper = np.ceil(numberOfDays/numberOfWindows)\n",
    "        ProbIndexLower = IndexPerWindowUpper - numberOfDays/numberOfWindows\n",
    "        indices = [IndexPerWindowLower,IndexPerWindowUpper]\n",
    "        weights = [ProbIndexLower,1-ProbIndexLower]\n",
    "        IndexPerWindow = int(np.random.choice(indices, p=weights))\n",
    "        WSUsed.append(IndexPerWindow)\n",
    "\n",
    "widgets=[' [', progressbar.Timer(), '] ',progressbar.Percentage(),progressbar.Bar(),' (', progressbar.ETA(), ') ',]\n",
    "\n",
    "startNum = 0\n",
    "endNum = numberOfDays\n",
    "dfFinal = []\n",
    "WSUsed2 = pd.DataFrame(WSUsed)\n",
    "for y in progressbar.progressbar(Subject_id, widgets=widgets):\n",
    "    startWind = 0\n",
    "    dfExp = df.copy(deep=True)\n",
    "    dfExp = dfExp[startNum:endNum]\n",
    "    dfExpAge = dfExp.AgeFix.max()\n",
    "    startNum = startNum + numberOfDays\n",
    "    endNum = endNum + numberOfDays\n",
    "    for z in range (numberOfWindows):\n",
    "        endWind = startWind + int(WSUsed2.iloc[z])\n",
    "        dfExp2s = dfExp[startWind:endWind]\n",
    "        dfExp2 = aggregationFunc(dfExp2s)\n",
    "        dfExp2['age'] = dfExpAge\n",
    "        dfExp2['subject_id'] = y\n",
    "        dfExp2['index_id'] = z\n",
    "        dfFinal.append(dfExp2)\n",
    "        startWind = endWind\n",
    "        \n",
    "dfFinal2 = pd.DataFrame(dfFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfExp2s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureArray = np.array(dfFinal2)\n",
    "numberOfFeatures = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal2.to_csv('DI/DATA_' + str(numberOfWindows) + '.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "48feb6360a00eb0f47f9c89bd4d436ba37b01dbe1c2db3c2c6dfcc0146625bee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
