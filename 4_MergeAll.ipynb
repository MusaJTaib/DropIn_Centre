{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Pre-processing Notebook 4 for 90days clients data</h2><br>\n",
    "<em> Pre-processing the data to achieve Time-Stampped Tables or ts-tables of each client for the first 90 days of interaction. Done for all the attributes </em>\n",
    "<br><em>Along with description of EDA, feature engineering</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import scipy as sci\n",
    "import scipy.special as scisp\n",
    "import scipy.stats as scist\n",
    "import datetime, copy, imp, sys\n",
    "\n",
    "sys.path.append('../../lib')\n",
    "\n",
    "from tqdm import tqdm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "tqdm.pandas()\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validClientsFirst90DaysDf2 = pd.read_hdf('validClientsFirst90DaysDf2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validClientsFirst90DaysDf2.tail(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Exploratory Data Analysis (EDA) Summary for feature engineering </h3>\n",
    "<br>\n",
    "1. <strong>Age</strong> of all the clients doesnt change in the first 90 days.<br> \n",
    "2. <strong>BarDuration:</strong> it is the bar/ban on a client from accessing the DI services. The entries can be numeric 2 days, 3 days, 5 days etc and Categorical like less than 24hrs, Lifetime, conditional etc <br>\n",
    "3. However there are a lot of cases where we can find a barDuration <strong>mismatch</strong> in the entries on a particular day. Hypothetical example: the barDuration entry is 2 days for client 123 for Sleep EntryType and 5 days for Log EntryType on the same day.<br>\n",
    "4. <strong>Location</strong> specifies the location in the the DI shelter where the client access the facility/sleeps. This attribute is to be ignored as this be unreliable in the long run.<br>\n",
    "5. <strong>Word counts</strong>: From GettingStarted.ipynb (master branch) each of the 32 buckets (below) has a number of associated words, the counts of these words were extarcted from the logs in order to maintain data anonymization and still provide useful insights from the logs: \n",
    "<br><br>Addiction,Bar,Biometrics,Brawl,CPS,Conflict,Death,EMS,Education,Employment,Financial,FriendsFamily,Gun,Health,Housing<br>ID,Indigenous,Justice,Knife,Medication,MentalHealth,NegativeWord,Overdose,PhysicalHealth,PhysicalViolence,PositiveWord,<br>Property,Seniors,SexualViolence,Spray,Supports,Weapon.<br>\n",
    "6. <strong> EmsLogFlag:</strong> is 1 in the log entry for an event where the EMS were called. Multiple log entries with EmsLogFlag also present on some days for a few clients.<br>\n",
    "7. <strong> PoliceLogFlag:</strong> is 1 in the log entry for an event where the police were called. Multiple log entries with PoliceLogFlag also present on some days for a few clients.<br>\n",
    "8. <strong>ClientState:</strong> The state of a particular client can change on a particular day as seen from the data. Eg: A client can be sober in the morning and intoxicated in the evening.<br>\n",
    "9. <strong>EntryType: </strong> Different types of entries present in the dataset: Bar, CounsellorsNotes, ProgressDetails, Log, or Sleep. Multiple entries of each type can be present on a particular day for each client.<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Raw Attribute Description and Feature Engineering </h3>\n",
    "<br>\n",
    "1. <strong>EmployeeId:</strong> Unique Employee Ids are counted to compute the total number of employees interacted with the client on a particular day. <br>\n",
    "2. ClientId - index <br>\n",
    "3. Date - index <br>\n",
    "4. <strong>Age: </strong>no change by date, same for a particular client across the first 90 days <br>\n",
    "5. <strong>BarDuration:</strong>maximum BarDuration in the dataset for a particular day taken of all. For pre-processing categorical entries are assigned values: warning 0.1 days, conditional 0.5 days, less than 24hrs 0.9 days, and lifetime 500 days. These values are replaced by the original categorical entries after taking the maximum. <br>\n",
    "6. <strong>Word Counts:</strong>For all the individual 32 word counts, sum of the individual word counts was computed for each day. This pre-processing step was performed in the the previous notebook (preProcessing_mergedCounts_90_Days_From_FirstSleepDate)<br>\n",
    "7. <strong>EmployeeIsCounsellor:</strong> Total number of councillor interactions of the client on a particular day computed by taking a daily sum of the EmployeeIsCouncellor column. <br>\n",
    "8. <strong>PoliceLogFlag:</strong> Total number of times police was called on a client on a particular day computed by taking a daily sum of the PoliceLogFlag column<br>\n",
    "9. <strong>EmsLogFlag:</strong> Total number of times EMS was called for a client on a particular day computed by taking a daily sum of the EmsLogFlag column <br>\n",
    "10. <strong>ClientState:</strong> Since the clients state can change on a particular day and states are categorical variables, hence each state type is used to compute new individual features. They indicate the client states on a particular day. These engineered features indicate whether a client was in that state or not. Hypothetical Eg. If client 123 was ever sober on a specific day then clientSoberState would be 1. These features are flag type hence they would be 1 even if multiple entries of sober state are found on a particular day.<br>\n",
    "11. <strong>EntryType: </strong>  similar to clientState, multiple new features are generated from this attribute to indicate the presence of a particular entry type on a particular day. These features are also flag type and indicate only the presence or absence of a specific entry on a particular day. Hypothetical Eg. If client 123 had a sleep entry on a specific day then ClientSleepEntry would be 1.<br>\n",
    "12. However EntryType of <strong>Bar</strong> is ignored due to the presence of barDuration which indicates the same information along with the exact amount of bar/ban from DI shelter. Hence this EntryTYpe would have been redundant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validClientsFirst90DaysDf2 = validClientsFirst90DaysDf2.set_index('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering \n",
    "- All functions which are Aggregates (sum) are DailyAggXYZ and All functions which count the total number of daily entries are DailyABCDCount. \n",
    "- Age doesnt change in a single day so all values are same. Hence, max taken for convience to append to the merged Dataframe\n",
    "- Client States values are used to engineer seprate binary feature vectors. The engineered features are flags and indicate the presence or absence of that state that particular day. Eg : if sober entry present in that day (1 or more sober entries) then ClientStateSober = 1\n",
    "- Bar duration has categorical and numerical entries. Both are stored as strings. Numerical vaklues are mapped to integer values and an assumption is made to assign numerical values to categorical entries of BarDuration\n",
    "- The aggregations are split into seprate functions due to constraints of the RAM memory\n",
    "- The computed individual aggregates are intially stored in temporary variables and then are appended to two dataframes depending upon type sequently. Categorical features to tempMergeCategorical and Non-Categorical features to tempMergeNonCategorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClientAge(tbl):\n",
    "    dayVal = tbl.Age.groupby(tbl.index.date).max().reset_index()\n",
    "    return dayVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DailyAggEmployeeIsCounsellor(tbl): #sum of total counsillor interactions\n",
    "    dayVal = tbl.EmployeeIsCounsellor.groupby(tbl.index.date).sum().reset_index() \n",
    "    return dayVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DailyAggEmsLogFlag(tbl): \n",
    "    dayVal = tbl.EmsLogFlag.groupby(tbl.index.date).sum().reset_index() \n",
    "    return dayVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DailyAggPoliceLogFlag(tbl): \n",
    "    dayVal = tbl.PoliceLogFlag.groupby(tbl.index.date).sum().reset_index() \n",
    "    return dayVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DailyEmployeeIdCount(tbl): \n",
    "    dayVal = tbl.EmployeeId.groupby(tbl.index.date).count().reset_index() \n",
    "    return dayVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClientStateSober(tbl): # flag\n",
    "    dayVal = np.sign(tbl.ClientState[tbl.ClientState=='Sober'].groupby(tbl[tbl.ClientState=='Sober'].index.date).count()).reset_index() \n",
    "    return dayVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClientStateUnder(tbl): # flag\n",
    "    dayVal = np.sign(tbl.ClientState[tbl.ClientState=='Under'].groupby(tbl[tbl.ClientState=='Under'].index.date).count()).reset_index() \n",
    "    return dayVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClientStateIntoxicated(tbl): # flag\n",
    "    dayVal = np.sign(tbl.ClientState[tbl.ClientState=='Intoxicated'].groupby(tbl[tbl.ClientState=='Intoxicated'].index.date).count()).reset_index() \n",
    "    return dayVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClientStateDrugged(tbl): # flag\n",
    "    dayVal = np.sign(tbl.ClientState[tbl.ClientState=='Drugged'].groupby(tbl[tbl.ClientState=='Drugged'].index.date).count()).reset_index() \n",
    "    return dayVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClientStateDruggedIntoxicated(tbl): # flag\n",
    "    dayVal = np.sign(tbl.ClientState[tbl.ClientState=='Drugged & Intoxicated'].groupby(tbl[tbl.ClientState=='Drugged & Intoxicated'].index.date).count()).reset_index() \n",
    "    return dayVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = {'1':1, '14':14, '21':21, '60':60, '5':5, '120':120, '90':90, '90':90,'90':90, '3':3, '7':7, '2':2,'Warning':0.1, '-24 Hours':0.9,'Life':500,'Conditional':0.5,'30':30}\n",
    "validClientsFirst90DaysDf2 = validClientsFirst90DaysDf2.replace({\"BarDuration\": di})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClientBarDuration(tbl): # barDuration: max of the entries kept if multiple entries present\n",
    "    dayVal = tbl.BarDuration.groupby(tbl.index.date).max().reset_index()\n",
    "    return dayVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClientSleepEntry(tbl): #indicates sleep entry on a day- Flag type\n",
    "    dayVal = np.sign(tbl.EntryType[tbl.EntryType=='Sleep'].groupby(tbl.EntryType[tbl.EntryType=='Sleep'].index.date).count()).reset_index() \n",
    "    return dayVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DailyCounsellorsNotesCount(tbl): # Count: total entries in a day\n",
    "    dayVal = tbl.EntryType[tbl.EntryType=='counsellorsNotes'].groupby(tbl.EntryType[tbl.EntryType=='counsellorsNotes'].index.date).count().reset_index() \n",
    "    return dayVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DailyProgressDetailsCount(tbl): \n",
    "    dayVal = tbl.EntryType[tbl.EntryType=='ProgressDetails'].groupby(tbl.EntryType[tbl.EntryType=='ProgressDetails'].index.date).count().reset_index() \n",
    "    return dayVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DailyLogEntryCount(tbl): # sum\n",
    "    dayVal = tbl.EntryType[tbl.EntryType=='Log'].groupby(tbl.EntryType[tbl.EntryType=='Log'].index.date).count().reset_index() \n",
    "    return dayVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bar entryType redundant- covered in barDuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Feature Engineering of categorical EntryType and ClientState </h3><br>\n",
    "- Pre-processing of Categorical features is different from non-categorical features as  Date is required as the index for feature engineering<br>\n",
    "- Index of non-categorial features is Day number    <br>\n",
    "- Date required as index beacuse not all days would have a particular type of entry or state. Hence it is required to have index Date, to later merge with the non-categorical features later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempFuncTbl1 = validClientsFirst90DaysDf2.groupby(\"ClientId\").progress_apply(ClientStateSober)\n",
    "\n",
    "tempFuncTbl2 = validClientsFirst90DaysDf2.groupby(\"ClientId\").progress_apply(ClientStateUnder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempFuncTbl1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDf = pd.DataFrame(tempFuncTbl1)\n",
    "tempDf = tempDf.reset_index(level=[0,1])\n",
    "tempDf = tempDf.rename(columns={'index':'Date','ClientState':'SoberState'})\n",
    "tempDf = tempDf.drop(columns=['level_1'])# to have only one Ind column at the end \n",
    "tempDf = tempDf.set_index(['ClientId','Date'])\n",
    "tempDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDf2 = pd.DataFrame(tempFuncTbl2)\n",
    "tempDf2 = tempDf2.reset_index(level=[0,1])\n",
    "tempDf2 = tempDf2.rename(columns={'index':'Date','ClientState':'UnderState'})\n",
    "tempDf2 = tempDf2.drop(columns=['level_1']) # to have only one Ind column at the end \n",
    "tempDf2 = tempDf2.set_index(['ClientId','Date'])\n",
    "tempDf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempMergeCategorical=tempDf.join(tempDf2, how ='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempFuncTbl2 = validClientsFirst90DaysDf2.groupby(\"ClientId\").progress_apply(ClientStateIntoxicated)\n",
    "tempDf2 = pd.DataFrame(tempFuncTbl2)\n",
    "tempDf2 = tempDf2.reset_index(level=[0,1])\n",
    "tempDf2 = tempDf2.rename(columns={'index':'Date','ClientState':'IntoxicatedState'})\n",
    "tempDf2 = tempDf2.drop(columns=['level_1']) # to have only one Ind column at the end \n",
    "tempDf2 = tempDf2.set_index(['ClientId','Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempMergeCategorical = tempMergeCategorical.join(tempDf2, how ='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempFuncTbl2 = validClientsFirst90DaysDf2.groupby(\"ClientId\").progress_apply(ClientStateDrugged)\n",
    "tempDf2 = pd.DataFrame(tempFuncTbl2)\n",
    "tempDf2 = tempDf2.reset_index(level=[0,1])\n",
    "tempDf2 = tempDf2.rename(columns={'index':'Date','ClientState':'DruggedState'})\n",
    "tempDf2 = tempDf2.drop(columns=['level_1'])# to have only one Ind column at the end \n",
    "tempDf2 = tempDf2.set_index(['ClientId','Date'])\n",
    "tempDf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempMergeCategorical = tempMergeCategorical.join(tempDf2, how ='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempFuncTbl2 = validClientsFirst90DaysDf2.groupby(\"ClientId\").progress_apply(ClientStateDruggedIntoxicated)\n",
    "tempDf2 = pd.DataFrame(tempFuncTbl2)\n",
    "tempDf2 = tempDf2.reset_index(level=[0,1])\n",
    "tempDf2 = tempDf2.rename(columns={'index':'Date','ClientState':'DruggedIntoxicatedState'})\n",
    "tempDf2 = tempDf2.drop(columns=['level_1'])# to have only one Ind column at the end \n",
    "tempDf2 = tempDf2.set_index(['ClientId','Date'])\n",
    "tempMergeCategorical = tempMergeCategorical.join(tempDf2, how ='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempFuncTbl2 = validClientsFirst90DaysDf2.groupby(\"ClientId\").progress_apply(ClientSleepEntry)\n",
    "tempDf2 = pd.DataFrame(tempFuncTbl2)\n",
    "tempDf2 = tempDf2.reset_index(level=[0,1])\n",
    "tempDf2 = tempDf2.rename(columns={'index':'Date','EntryType':'SleepEntry'})\n",
    "tempDf2 = tempDf2.drop(columns=['level_1'])# to have only one Ind column at the end \n",
    "tempDf2 = tempDf2.set_index(['ClientId','Date'])\n",
    "tempMergeCategorical = tempMergeCategorical.join(tempDf2, how ='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempFuncTbl2 = validClientsFirst90DaysDf2.groupby(\"ClientId\").progress_apply(DailyCounsellorsNotesCount)\n",
    "tempDf2 = pd.DataFrame(tempFuncTbl2)\n",
    "tempDf2 = tempDf2.reset_index(level=[0,1])\n",
    "tempDf2 = tempDf2.rename(columns={'index':'Date','EntryType':'CounsellorNotes'})\n",
    "tempDf2 = tempDf2.drop(columns=['level_1'])# to have only one Ind column at the end \n",
    "tempDf2 = tempDf2.set_index(['ClientId','Date'])\n",
    "tempMergeCategorical = tempMergeCategorical.join(tempDf2, how ='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempFuncTbl2= validClientsFirst90DaysDf2.groupby(\"ClientId\").progress_apply(DailyProgressDetailsCount)\n",
    "tempDf2 = pd.DataFrame(tempFuncTbl2)\n",
    "tempDf2 = tempDf2.reset_index(level=[0,1])\n",
    "tempDf2 = tempDf2.rename(columns={'index':'Date','EntryType':'ProgressDetails'})\n",
    "tempDf2 = tempDf2.drop(columns=['level_1'])# to have only one Ind column at the end \n",
    "tempDf2 = tempDf2.set_index(['ClientId','Date'])\n",
    "tempMergeCategorical = tempMergeCategorical.join(tempDf2, how ='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempFuncTbl2 = validClientsFirst90DaysDf2.groupby(\"ClientId\").progress_apply(DailyLogEntryCount)\n",
    "tempDf2 = pd.DataFrame(tempFuncTbl2)\n",
    "tempDf2 = tempDf2.reset_index(level=[0,1])\n",
    "tempDf2 = tempDf2.rename(columns={'index':'Date','EntryType':'LogEntry'})\n",
    "tempDf2 = tempDf2.drop(columns=['level_1'])# to have only one Ind column at the end \n",
    "tempDf2 = tempDf2.set_index(['ClientId','Date'])\n",
    "tempMergeCategorical = tempMergeCategorical.join(tempDf2, how ='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempMergeCategorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tempMergeCategorical  - Would need to set all the index back to Ind to zero-padd the df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature Engineering of non-categorical features</h3> <br>\n",
    "- Except barDuration all the features below have non-categorical values. For pre-processing the categorial values of barDuration are converted into numerical values. <br>\n",
    "- For pre-processing day number used as index <br>\n",
    "- To merge correctly with the categorial features, the index is changed to Date before merging <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDf = validClientsFirst90DaysDf2.groupby(\"ClientId\").progress_apply(DailyEmployeeIdCount)\n",
    "tempDf = tempDf.reset_index(level=[0,1])\n",
    "tempDf['level_1']=tempDf['level_1']+1\n",
    "tempDf = tempDf.rename(columns={'level_1':'Ind','index':'Date'})\n",
    "tempDf = tempDf.set_index(['ClientId','Ind'])\n",
    "tempDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDf2 = validClientsFirst90DaysDf2.groupby(\"ClientId\").progress_apply(ClientAge)\n",
    "tempDf2 = tempDf2.reset_index(level=[0,1])\n",
    "tempDf2['level_1']=tempDf2['level_1']+1\n",
    "tempDf2 = tempDf2.rename(columns={'level_1':'Ind','index':'Date'})\n",
    "tempDf2 = tempDf2.set_index(['ClientId','Ind'])\n",
    "tempDf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDf2 = tempDf2.drop(columns=['Date']) # to have only one Date column at the end \n",
    "tempMergeNonCategorical = tempDf.join(tempDf2, how ='outer')\n",
    "tempMergeNonCategorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDf2 = validClientsFirst90DaysDf2.groupby(\"ClientId\").progress_apply(DailyAggEmployeeIsCounsellor)\n",
    "tempDf2 = tempDf2.reset_index(level=[0,1])\n",
    "tempDf2['level_1'] = tempDf2['level_1']+1\n",
    "tempDf2 = tempDf2.rename(columns={'level_1':'Ind','index':'Date'})\n",
    "tempDf2 = tempDf2.set_index(['ClientId','Ind'])\n",
    "tempDf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDf2 = tempDf2.drop(columns=['Date'])\n",
    "tempMergeNonCategorical = tempMergeNonCategorical.join(tempDf2, how ='outer')\n",
    "tempMergeNonCategorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDf2 = validClientsFirst90DaysDf2.groupby(\"ClientId\").progress_apply(DailyAggEmsLogFlag)\n",
    "tempDf2 = tempDf2.reset_index(level=[0,1])\n",
    "tempDf2['level_1']=tempDf2['level_1']+1\n",
    "tempDf2 = tempDf2.rename(columns={'level_1':'Ind','index':'Date'})\n",
    "tempDf2 = tempDf2.set_index(['ClientId','Ind'])\n",
    "tempDf2 = tempDf2.drop(columns=['Date'])\n",
    "tempMergeNonCategorical = tempMergeNonCategorical.join(tempDf2, how ='outer')\n",
    "tempMergeNonCategorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDf2 = validClientsFirst90DaysDf2.groupby(\"ClientId\").progress_apply(DailyAggPoliceLogFlag)\n",
    "tempDf2 = tempDf2.reset_index(level=[0,1])\n",
    "tempDf2['level_1']=tempDf2['level_1']+1\n",
    "tempDf2 = tempDf2.rename(columns={'level_1':'Ind','index':'Date'})\n",
    "tempDf2 = tempDf2.set_index(['ClientId','Ind'])\n",
    "tempDf2 = tempDf2.drop(columns=['Date'])\n",
    "tempMergeNonCategorical = tempMergeNonCategorical.join(tempDf2, how ='outer')\n",
    "tempMergeNonCategorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validClientsFirst90DaysDf2['BarDuration'].dtype)\n",
    "\n",
    "X2 = validClientsFirst90DaysDf2['BarDuration'].unique()\n",
    "print(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validClientsFirst90DaysDf2['BarDuration'] = validClientsFirst90DaysDf2['BarDuration'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = validClientsFirst90DaysDf2['BarDuration'].unique()\n",
    "print(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDf2 = validClientsFirst90DaysDf2.groupby(\"ClientId\").progress_apply(ClientBarDuration)\n",
    "tempDf2 = tempDf2.reset_index(level=[0,1])\n",
    "tempDf2['level_1']=tempDf2['level_1']+1\n",
    "tempDf2 = tempDf2.rename(columns={'level_1':'Ind','index':'Date'})\n",
    "tempDf2 = tempDf2.set_index(['ClientId','Ind'])\n",
    "tempDf2 = tempDf2.drop(columns=['Date'])\n",
    "tempMergeNonCategorical = tempMergeNonCategorical.join(tempDf2, how ='outer')\n",
    "tempMergeNonCategorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempMergeNonCategorical = tempMergeNonCategorical.reset_index(level=[0,1])\n",
    "tempMergeNonCategorical = tempMergeNonCategorical.set_index(['ClientId','Date'])\n",
    "tempMergeNonCategorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDfMergeAll = tempMergeNonCategorical.join(tempMergeCategorical, how ='outer')\n",
    "tempDfMergeAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDfMergeAll = tempDfMergeAll.reset_index(level=[0,1])\n",
    "tempDfMergeAll = tempDfMergeAll.set_index(['ClientId','Ind'])\n",
    "tempDfMergeAll"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Merging Word-counts</h3><br>\n",
    "- Merging the pre-processed word counts stored as mergedCounts90daysDF.h5 with the the features pre-processed in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedCounts90daysDF = pd.read_hdf('mergedCounts_90DaysDf2.h5')\n",
    "mergedCounts90daysDF = mergedCounts90daysDF.drop(columns=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMergeAll = tempDfMergeAll.join(mergedCounts90daysDF, how ='outer')\n",
    "\n",
    "dfMergeAll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anyFeature = tempDf.reset_index(level=1) # using any feature to create a Blank TS-Table first\n",
    "anyFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BlanktsTbl(tbl):\n",
    "    dayy = []\n",
    "    for i in range (1,91):\n",
    "        dayy.append(i)\n",
    "    dayy = pd.DataFrame(dayy)\n",
    "    \n",
    "    return dayy\n",
    "tsTblBlank = anyFeature.groupby(\"ClientId\").progress_apply(BlanktsTbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsTblBlank = tsTblBlank.reset_index(level=[0,1])\n",
    "tsTblBlank = tsTblBlank.set_index(['ClientId',0])\n",
    "tsTblBlank.level_1 = 0\n",
    "tsTblBlank = tsTblBlank.rename_axis(index=['ClientId', 'Ind'])\n",
    "tsTblBlank = tsTblBlank.rename(columns={'level_1':'EncodedVector'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsTblBlank.head(182)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validClientsFirst90DaysDf2 = pd.read_hdf('validClientsFirst90DaysDf2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the day number from the first registration date of each entry \n",
    "- Useful to differentiate between the index number of the record and the Day number \n",
    "- Client number 2532818 taken as an example to illustrate this difference. 4 records present for 4 different days. Since there is no record for 2017-05-24 (day 4), the day number from the first registration date (2017-05-22) is 5 for the record number 4 on 2017-05-26.\n",
    "- The day numbers are the calender days from the first access date for each client ID. Day number 1 is the first access day for each client ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenShelterAcessIndex(tbl):\n",
    "    dates = tbl.Date.dt.date.drop_duplicates().sort_values()   #For exact day numer \n",
    "    dateFirst = dates.iloc[0]  \n",
    "    dayNumber = dates - dateFirst \n",
    "    return pd.DataFrame({\n",
    "        'Date': dates,                 # Date of each stay.\n",
    "        'Ind': range(1,len(dates)+1), \n",
    "        'Day': (dayNumber/np.timedelta64(1, 'D') + 1).astype(int)# Index of each stay.\n",
    "    })\n",
    "        \n",
    "shelterAcessIndx = validClientsFirst90DaysDf2.groupby('ClientId').progress_apply(GenShelterAcessIndex)\n",
    "shelterAcessIndx = shelterAcessIndx.reset_index(level=[0,1])\n",
    "shelterAcessIndx[shelterAcessIndx.ClientId == 2532818]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfShelterAcess2 = shelterAcessIndx.set_index(['ClientId','Ind'])\n",
    "dfShelterAcess2 = dfShelterAcess2.drop(columns=['Date', 'level_1'])  #drop date and level 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Merging features with day numbers and index of records</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfShelterAccessFeatures = dfShelterAcess2.join(dfMergeAll, how='left')\n",
    "dfShelterAccessFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Encoded vector and final padded dataframe: tsTblPadded </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfShelterAccessFeatures = dfShelterAccessFeatures.reset_index(level=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shelterFeaturesDayIndex = dfShelterAccessFeatures.set_index(['ClientId','Day'])\n",
    "shelterFeaturesDayIndex = shelterFeaturesDayIndex.rename(columns={'Ind':'index'})\n",
    "shelterFeaturesDayIndex = shelterFeaturesDayIndex.rename_axis(['ClientId','Ind'])\n",
    "tsTblPadded = pd.merge(tsTblBlank,shelterFeaturesDayIndex, how='left', left_index=True, right_index=True)\n",
    "tsTblPadded.EncodedVector = tsTblPadded.Date.notnull()\n",
    "tsTblPadded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsTblPadded = tsTblPadded.rename_axis([\"ClientId\",\"Day\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di2 = {0.1:'Warning',0.9:'-24 Hours',500:'Life',0.5:'Conditional'}\n",
    "tsTblPadded = tsTblPadded.replace({\"BarDuration\": di2})\n",
    "tsTblPadded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsTblPadded[tsTblPadded.BarDuration.notnull()].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Test case</h3> <br>\n",
    "- To demonstarate the final dataframe but with reset level to print properly<br>\n",
    "- Final dataset is a multi-index data-frame with clientId and Day as index axis<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsTblPadded_Columns = tsTblPadded.reset_index()\n",
    "tsTblPadded = tsTblPadded.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsTblPadded.head(1).transpose().index #all the final features after pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Saving the final dataframe to disc</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsTblPadded.to_hdf('clientTsTables90DaysPaddedDF.h5',key='df',mode='w')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f3ba9e726005c067fbc0eaab20e31f21cd7f7e132fec231b7dd4c5a2981fed5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
