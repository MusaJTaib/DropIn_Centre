{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from functools import reduce\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Windows: 1,2,3,6,12,22,45,90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfWindows = 6\n",
    "Restriction = '90'\n",
    "ep = 500\n",
    "numberOfFeatures = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "los_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSetB2 = pd.DataFrame()\n",
    "FeatureSetB3 = pd.DataFrame()\n",
    "FeatureSetB4 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSetB1 = pd.read_csv('DI/DATA_Base.csv') #Split\n",
    "FeatureSetB2 = pd.read_csv(f'DI/DATA_{numberOfWindows}.csv')#Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall) / (precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSetB1.drop(\"Unnamed: 0\",axis=1,inplace = True)\n",
    "FeatureSetB2.drop(\"Unnamed: 0\",axis=1,inplace = True)\n",
    "\n",
    "FeatureSetB1 = FeatureSetB1.fillna(0)\n",
    "FeatureSetB2 = FeatureSetB2.fillna(0)\n",
    "\n",
    "FeatureMortality = pd.read_csv('DI/Sleep_Tbl.csv') #Labels\n",
    "FeatureMortality.drop(\"Unnamed: 0\",axis=1,inplace = True)\n",
    "FeatureMortality.rename(columns={'ClientId':'subject_id'},inplace=True)\n",
    "\n",
    "FeatureSetB1.sort_values(by=['subject_id'], ascending=True,inplace=True)\n",
    "\n",
    "FeatureMortality.sort_values(by=['subject_id'], ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id = pd.DataFrame()\n",
    "subject_id = FeatureSetB1.subject_id\n",
    "subject_id.drop_duplicates(keep = 'first', inplace = True)\n",
    "subject_id.reset_index(drop=True,inplace=True)\n",
    "NumSubjects = len(subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = FeatureMortality['subject_id'].isin(subject_id)\n",
    "FeatureMortality = FeatureMortality[X]\n",
    "FeatureMortality.sort_values(by=['subject_id'], ascending=True,inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id = pd.DataFrame()\n",
    "subject_id = FeatureMortality.subject_id\n",
    "subject_id.drop_duplicates(keep = 'first', inplace = True)\n",
    "subject_id.reset_index(drop=True,inplace=True)\n",
    "NumSubjects = len(subject_id)\n",
    "X = FeatureSetB1['subject_id'].isin(subject_id)\n",
    "FeatureSetB1 = FeatureSetB1[X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureMortality.Flags[FeatureMortality.Flags == 1] = 0\n",
    "FeatureMortality.Flags[FeatureMortality.Flags == 2] = 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureMortality['Flags'].value_counts()         #Chronic is 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = pd.DataFrame()\n",
    "Labels['subject_id'] = FeatureMortality['subject_id']\n",
    "Labels['Flags'] = FeatureMortality['Flags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = FeatureSetB1\n",
    "X_1 = [X,y]\n",
    "\n",
    "X_2 = reduce(lambda  left,right: pd.merge(left,right,on=['subject_id'],how='outer'), X_1)\n",
    "X_2.sort_values(by=['subject_id'], ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = X_2.dropna(subset=['Flags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id = pd.DataFrame()\n",
    "subject_id = X_2.subject_id\n",
    "subject_id.drop_duplicates(keep = 'first', inplace = True)\n",
    "subject_id.reset_index(drop=True,inplace=True)\n",
    "NumSubjects = len(subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = FeatureMortality['subject_id'].isin(subject_id)\n",
    "FeatureMortality = FeatureMortality.reset_index(drop=True)\n",
    "FeatureMortality = FeatureMortality[X]\n",
    "FeatureMortality.sort_values(by=['subject_id'], ascending=True,inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_age = X_2['age'].mean()\n",
    "X_emp = X_2['emp'].mean()\n",
    "X_emc = X_2['emc'].mean()\n",
    "X_sleep = X_2['sleep'].mean()\n",
    "X_ssAgg = X_2['ssAgg'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2.loc[(X_2.age < X_age),  'age_Group'] = 'Young'\n",
    "X_2.loc[(X_2.age >= X_age),  'age_Group'] = 'Old'\n",
    "\n",
    "X_2.loc[(X_2.emp < X_emp),  'emp_Group'] = 'Low'\n",
    "X_2.loc[(X_2.emp >= X_emp),  'emp_Group'] = 'High'\n",
    "\n",
    "X_2.loc[(X_2.emc < X_emc),  'emc_Group'] = 'Low'\n",
    "X_2.loc[(X_2.emc >= X_emc),  'emc_Group'] = 'High'\n",
    "\n",
    "X_2.loc[(X_2.sleep < X_sleep),  'sleep_Group'] = 'Low'\n",
    "X_2.loc[(X_2.sleep >= X_sleep),  'sleep_Group'] = 'High'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2['Flags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2['age_Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2['emp_Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2['emc_Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2['sleep_Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = FeatureSetB1\n",
    "\n",
    "X_train1, X_test = train_test_split(X_2, test_size=0.25, stratify=X_2[['Flags']], shuffle=True,random_state=42)#,'age_Group','emp_Group','emc_Group','sleep_Group']]#,'AIDS','MetaStatic','Hematologic'#,'GCSEyes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1['Flags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1['sleep_Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1['emc_Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1['emp_Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1['age_Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = train_test_split(X_train1, test_size=0.2, random_state=42, stratify=X_train1[['Flags']], shuffle=True)#,'age_Group','emp_Group','emc_Group','sleep_Group']], shuffle=True)#, shuffle=True)#,'GCSEyes']],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['Flags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val['Flags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Flags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subject_Test = pd.DataFrame()\n",
    "Subject_Test = X_test.subject_id\n",
    "\n",
    "Subject_Train = pd.DataFrame()\n",
    "Subject_Train = X_train.subject_id\n",
    "\n",
    "Subject_Val = pd.DataFrame()\n",
    "Subject_Val = X_val.subject_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = FeatureMortality['subject_id'].isin(Subject_Train)\n",
    "y_train = FeatureMortality[X]\n",
    "\n",
    "X = FeatureMortality['subject_id'].isin(Subject_Test)\n",
    "y_test = FeatureMortality[X]\n",
    "\n",
    "X = FeatureMortality['subject_id'].isin(Subject_Val)\n",
    "y_val = FeatureMortality[X]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.sort_values(by=['subject_id'], ascending=True,inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = FeatureSetB2['subject_id'].isin(Subject_Train)\n",
    "X_train = FeatureSetB2[X]\n",
    "\n",
    "\n",
    "X = FeatureSetB2['subject_id'].isin(Subject_Test)\n",
    "X_test = FeatureSetB2[X]\n",
    "\n",
    "\n",
    "X = FeatureSetB2['subject_id'].isin(Subject_Val)\n",
    "X_val = FeatureSetB2[X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_shape = X_train.shape\n",
    "Test_shape = X_test.shape\n",
    "Val_shape = X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train.drop(\"subject_id\",axis=1,inplace = True)\n",
    "\n",
    "\n",
    "X_test.drop(\"subject_id\",axis=1,inplace = True)\n",
    "\n",
    "\n",
    "X_val.drop(\"subject_id\",axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "\n",
    "X_test = X_test.to_numpy()\n",
    "\n",
    "X_val = X_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(int(Train_shape[0]/numberOfWindows),numberOfWindows*numberOfFeatures)\n",
    "X_test = X_test.reshape(int(Test_shape[0]/numberOfWindows),numberOfWindows*numberOfFeatures)\n",
    "X_val = X_val.reshape(int(Val_shape[0]/numberOfWindows),numberOfWindows*numberOfFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train4 = X_train\n",
    "\n",
    "X_test4 = X_test\n",
    "\n",
    "X_val4 = X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train['Flags']\n",
    "y_train = y_train.to_numpy()\n",
    "y_train = y_train.flatten()\n",
    "\n",
    "y_test = y_test['Flags']\n",
    "y_test = y_test.to_numpy()\n",
    "y_test = y_test.flatten()\n",
    "\n",
    "y_val = y_val['Flags']\n",
    "y_val = y_val.to_numpy()\n",
    "y_val = y_val.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,Flatten, Activation\n",
    "from sklearn import metrics\n",
    "from keras.layers import LSTM\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "mod=sys.modules[__name__]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "acc_score = []\n",
    "re_score = []\n",
    "pre_score = []\n",
    "history_1 = []\n",
    "f_score = []\n",
    "f_score_2 = []\n",
    "acc_macro_score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfFeatures2 = X_test4.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.backend import epsilon\n",
    "\n",
    "def weighted_cross_entropy(class_weight=(0.1, 0.9)):\n",
    "    \"\"\"\n",
    "    Returns a weighted cross-entropy loss function, considering the given class weights.\n",
    "    \"\"\"\n",
    "    class_weight = tf.constant(class_weight, dtype=tf.float32)\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon(), 1. - epsilon())\n",
    "\n",
    "        cross_entropy_loss = - y_true * tf.math.log(y_pred) * class_weight[1] - \\\n",
    "                             (1.0 - y_true) * tf.math.log(1.0 - y_pred) * class_weight[0]\n",
    "\n",
    "        loss = tf.reduce_mean(cross_entropy_loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_true = K.cast(y_true, 'float32')  # Casting y_true to float32\n",
    "        epsilon = K.epsilon()  # Small constant to prevent log(0)\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)  # Clipping y_pred values\n",
    "        pt_1 = y_true * K.pow(1. - y_pred, gamma) * K.log(y_pred)\n",
    "        pt_0 = (1. - y_true) * K.pow(y_pred, gamma) * K.log(1. - y_pred)\n",
    "        return -K.mean(alpha * pt_1 + (1. - alpha) * pt_0)\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_loss = weighted_cross_entropy(class_weight=(0.2,2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Metric\n",
    "\n",
    "class MacroAccuracy(Metric):\n",
    "    def __init__(self, name=\"macro_accuracy\", **kwargs):\n",
    "        super(MacroAccuracy, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"tp\", initializer=\"zeros\")\n",
    "        self.false_positives = self.add_weight(name=\"fp\", initializer=\"zeros\")\n",
    "        self.true_negatives = self.add_weight(name=\"tn\", initializer=\"zeros\")\n",
    "        self.false_negatives = self.add_weight(name=\"fn\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(y_true, tf.float32)  # Cast y_true to float32\n",
    "        y_pred = tf.round(y_pred)\n",
    "        self.true_positives.assign_add(tf.reduce_sum(y_true * y_pred))\n",
    "        self.false_positives.assign_add(tf.reduce_sum((1 - y_true) * y_pred))\n",
    "        self.true_negatives.assign_add(tf.reduce_sum((1 - y_true) * (1 - y_pred)))\n",
    "        self.false_negatives.assign_add(tf.reduce_sum(y_true * (1 - y_pred)))\n",
    "\n",
    "    def result(self):\n",
    "        precision_0 = self.true_negatives / (self.true_negatives + self.false_negatives + 1e-7)\n",
    "        recall_0 = self.true_negatives / (self.true_negatives + self.false_positives + 1e-7)\n",
    "        accuracy_0 = (precision_0 + recall_0) / 2\n",
    "\n",
    "        precision_1 = self.true_positives / (self.true_positives + self.false_positives + 1e-7)\n",
    "        recall_1 = self.true_positives / (self.true_positives + self.false_negatives + 1e-7)\n",
    "        accuracy_1 = (precision_1 + recall_1) / 2\n",
    "\n",
    "        macro_accuracy = (accuracy_0 + accuracy_1) / 2\n",
    "        return macro_accuracy\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.true_positives.assign(0)\n",
    "        self.false_positives.assign(0)\n",
    "        self.true_negatives.assign(0)\n",
    "        self.false_negatives.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_macro_accuracy', patience = 25, mode='max',restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "scaler1 = StandardScaler().fit(X_train4)\n",
    "X_train4 = scaler1.transform(X_train4)\n",
    "X_test4 = scaler1.transform(X_test4)\n",
    "X_val4 = scaler1.transform(X_val4)\n",
    "\n",
    "X_train4R, y_trainR = X_train4, y_train\n",
    "\n",
    "for x in range(3):\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.Input(shape=(numberOfFeatures2,)))\n",
    "\n",
    "    model.add(Dense(8192))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(2048))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "\n",
    "    opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.00075) # Increased learning rate\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=opt, metrics=[MacroAccuracy()])#from_logits=True\n",
    "\n",
    "    class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_trainR), y=y_trainR)\n",
    "    class_weights_dict = dict(zip(np.unique(y_trainR), class_weights))\n",
    "\n",
    "    history = model.fit(X_train4R, y_trainR, epochs=250, batch_size=1024, validation_data=(X_val4, y_val), shuffle=True, class_weight=class_weights_dict, callbacks=[stop_early])\n",
    "    history_1.append(history)\n",
    "\n",
    "    y_preds = model.predict(X_test4)\n",
    "    y_preds = y_preds.flatten()\n",
    "    y_pred = list(map(lambda x: 0 if x<0.45 else 1, y_preds))\n",
    "\n",
    "    y_actu = pd.Series(y_test)\n",
    "    y_pred = pd.Series(y_pred)\n",
    "\n",
    "    sensitivity = recall_score(y_actu, y_pred)\n",
    "    precision = precision_score(y_actu, y_pred)\n",
    "    f1_value = f1_score(y_actu, y_pred, average='macro')\n",
    "    f1_value_2 = f1_score(y_actu, y_pred)\n",
    "    accuracy = accuracy_score(y_actu, y_pred)\n",
    "\n",
    "    acc_score.append(accuracy)\n",
    "    re_score.append(sensitivity)\n",
    "    pre_score.append(precision)\n",
    "    f_score.append(f1_value)\n",
    "    f_score_2.append(f1_value_2)\n",
    "\n",
    "    matrix = matrix2 = confusion_matrix(y_actu, y_pred)\n",
    "    cm_display = ConfusionMatrixDisplay(confusion_matrix=matrix2)\n",
    "    Accuracies = matrix.diagonal() / matrix.sum(axis=1)\n",
    "    Less10D = Accuracies[0]\n",
    "    Greater10D = Accuracies[1]\n",
    "    accuracy_macro = (Greater10D + Less10D) / 2\n",
    "    acc_macro_score.append(accuracy_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "avg_acc_score = sum(acc_score)/k\n",
    "avg_recall_score = sum(re_score)/k\n",
    "avg_precision_score = sum(pre_score)/k\n",
    "avg_f1_score = sum(f_score)/k\n",
    "avg_f1_score_2 = sum(f_score_2)/k\n",
    "avg_acc_macro_score = sum(acc_macro_score)/k\n",
    "\n",
    "accuracy_macro = avg_acc_macro_score\n",
    "sensitivity = avg_recall_score\n",
    "precision = avg_precision_score\n",
    "accuracy = avg_acc_score\n",
    "f1_score = avg_f1_score\n",
    "f1_score_2 = avg_f1_score_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def calculate_standard_deviation(numbers):\n",
    "    n = len(numbers)\n",
    "    mean = sum(numbers) / n\n",
    "    variance = sum((x - mean) ** 2 for x in numbers) / n\n",
    "    std_dev = math.sqrt(variance)\n",
    "    return std_dev\n",
    "\n",
    "std_acc = calculate_standard_deviation(acc_score)\n",
    "std_acc_macro = calculate_standard_deviation(acc_macro_score)\n",
    "std_recall = calculate_standard_deviation(re_score)\n",
    "std_precision = calculate_standard_deviation(pre_score)\n",
    "std_f1_score = calculate_standard_deviation(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_min = min(re_score)\n",
    "sensitivity_max = max(re_score)\n",
    "\n",
    "precision_min = min(pre_score)\n",
    "precision_max = max(pre_score)\n",
    "\n",
    "accuracy_min = min(acc_score)\n",
    "accuracy_max = max(acc_score)\n",
    "\n",
    "accuracy_macro_min = min(acc_macro_score)\n",
    "accuracy_macro_max = max(acc_macro_score)\n",
    "\n",
    "f1_score_min = min(f_score)\n",
    "f1_score_max = max(f_score)\n",
    "\n",
    "f1_score_min_2 = min(f_score_2)\n",
    "f1_score_max_2 = max(f_score_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Avg accuracy : {}'.format(avg_acc_score))\n",
    "print('Avg Reccall : {}'.format(avg_recall_score))\n",
    "print('Avg Precision : {}'.format(avg_precision_score))\n",
    "print('Avg F1_score : {}'.format(avg_f1_score))\n",
    "print('Avg F1_score_NoMacro : {}'.format(avg_f1_score_2))\n",
    "print('Avg accuracy_macro : {}'.format(avg_acc_macro_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for history in history_1:\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for history in history_1:\n",
    "    plt.plot(history.history['macro_accuracy'])\n",
    "    plt.plot(history.history['val_macro_accuracy'])\n",
    "    plt.title('Model F1')\n",
    "    plt.ylabel('F1')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "\n",
    "csv_columns = ['model-type','precision','sensitivity','f1-score','accuracy','accuracy_macro','NumberOfWindows','Epochs','Run_Time','Restriction','Acc_Lesser','Acc_Greater']\n",
    "dict_data = [{'model-type':'ANN', 'precision': precision,'sensitivity': sensitivity,'f1-score': f1_score,'accuracy': accuracy,'accuracy_macro': accuracy_macro,'NumberOfWindows':numberOfWindows,\"Epochs\":ep,'Run_Time':runtime,'Restriction' : Restriction,'Acc_Lesser':Less10D,'Acc_Greater':Greater10D}]\n",
    "metric_file = \"Results/Episodic_ANN_Max_FR.csv\"\n",
    "\n",
    "file_exists = os.path.isfile(metric_file)\n",
    "try:\n",
    "    with open(metric_file, 'a') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        for data in dict_data:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
